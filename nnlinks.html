<!DOCTYPE NETSCAPE-Bookmark-file-1>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=UTF-8">
<TITLE>Bookmarks</TITLE>
<H1>Bookmarks</H1>
<DL><p>
    <DT><H3 >Bookmarks Bar</H3>
        <DT><H3 >DL</H3>
        <DL><p>
            <DT><H3 >Articles</H3>
            <DL><p>
                <DT><A HREF="https://medium.com/@NathanBenaich/6-areas-of-artificial-intelligence-to-watch-closely-673d590aa8aa#.qcwk6t3nt" >6 areas of AI&amp;ML to watch (come back to this routinely)</A>
                <DT><A HREF="http://karpathy.github.io/2015/10/25/selfie/" >What a Deep Neural Network thinks about your #selfie</A>
                <DT><A HREF="https://medium.com/chingu/neuron-explained-using-simple-algebra-example-b18f5e280845#.lfgq14m5d" >Neuron explained using simple algebra – Chingu – Medium</A>
                <DT><A HREF="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471#.x0cps9td4" >ML is Fun (World&#39;s easiest intro to ML)</A>
                <DT><A HREF="https://medium.com/transmission-newsletter/identifying-rare-diseases-lung-cancer-more-with-deep-learning-10d931681ccc#.x35cc5wlk" >Identifying rare diseases, lung cancer &amp; more with Deep Learning – Transmission Newsletter – Medium</A>
                <DT><A HREF="http://sebastianruder.com/optimizing-gradient-descent/" >An overview of gradient descent optimization algorithms</A>
                <DT><A HREF="https://medium.com/@dhruvp/how-to-write-a-neural-network-to-play-pong-from-scratch-956b57d4f6e0#.7n0bn63v9" >Write an AI to win at Pong from scratch with Reinforcement Learning – Medium</A>
                <DT><A HREF="http://www.kdnuggets.com/2016/10/artificial-intelligence-deep-learning-neural-networks-explained.html" >Artificial Intelligence, Deep Learning, and Neural Networks, Explained</A>
                <DT><A HREF="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Nguyen_Deep_Neural_Networks_2015_CVPR_paper.pdf" >Deep Neural Networks Are Easily Fooled: High Confidence Predictions for Unrecognizable Images</A>
                <DT><A HREF="https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/" >Beginner&#39;s Guide To Convolutional Neural Networks – Adit Deshpande – CS Undergrad at UCLA (&#39;19)</A>
            </DL><p>
            <DT><H3 >Books</H3>
            <DL><p>
                <DT><A HREF="http://www.deeplearningbook.org/" >AdvBk:  Deep Learning (Ian Goodfellow)</A>
                <DT><A HREF="http://neuralnetworksanddeeplearning.com/" >IntroBk: NN and DL (M. Nielsen)</A>
                <DT><A HREF="https://www.manning.com/books/grokking-deep-learning" >COURSE TEXTBOOK:  Manning | Grokking Deep Learning</A>
            </DL><p>
            <DT><H3 >Competitions</H3>
            <DL><p>
                <DT><A HREF="https://www.kaggle.com/c/word2vec-nlp-tutorial#part-3-more-fun-with-word-vectors" >Bag of Words Meets Bags of Popcorn | Kaggle</A>
            </DL><p>
            <DT><H3 >CNNs</H3>
            <DL><p>
                <DT><A HREF="http://colah.github.io/posts/2014-07-Conv-Nets-Modular/" >2014:  Olah:  Conv Nets: A Modular Perspective</A>
                <DT><A HREF="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf" >2012:  Krizhevsky et al:  ImageNet classification w/ deep CNNs</A>
                <DT><A HREF="https://github.com/vdumoulin/conv_arithmetic" >Convolution Animations</A>
                <DT><A HREF="http://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html" >ConvNetJS demo: Classify toy 2D data</A>
                <DT><A HREF="http://colah.github.io/posts/2014-07-Understanding-Convolutions/" >Understanding Convolutions - colah&#39;s blog</A>
                <DT><A HREF="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/" >Understanding Convolutional Neural Networks for NLP – WildML</A>
                <DT><A HREF="http://deeplearning.net/tutorial/lenet.html" >Convolutional Neural Networks (LeNet) </A>
                <DT><A HREF="http://www.matthewzeiler.com/pubs/arxive2013/eccv2014.pdf" >Visualizing and Understanding CNNs</A>
                <DT><A HREF="https://arxiv.org/pdf/1312.4400v3.pdf" >2014: Lin et al: Network in Network (1x1 Convolutions)</A>
                <DT><A HREF="https://arxiv.org/pdf/1409.4842v1.pdf" >2014: Szegedy et al:  Going deeper w/ convolutions (Google)</A>
            </DL><p>
            <DT><H3 >Courses</H3>
            <DL><p>
                <DT><A HREF="https://openai.com/blog/openai-gym-beta/" >OpenAI Gym</A>
                <DT><A HREF="https://www.bayareadlschool.org/schedule" >bayareadlschool | presentations</A>
                <DT><A HREF="https://webdocs.cs.ualberta.ca/~sutton/book/the-book-2nd.html" >Sutton &amp; Barto Book: Reinforcement Learning: An Introduction</A>
                <DT><A HREF="https://www.youtube.com/watch?v=aUrX-rP_ss4" >John Schulman: Deep Reinforcement Learning   (YouTube)</A>
                <DT><H3 >Udacity__DL-NDF</H3>
                <DL><p>
                    <DT><A HREF="https://classroom.udacity.com/nanodegrees/nd101/syllabus" >Udacity-DL NanoDegree Main Page</A>
                    <DT><A HREF="https://medium.com/udacity/deep-learning-nanodegree-foundation-program-syllabus-in-depth-2eb19d014533#.4haglhmbf" >Syllabus Overview (blog)</A>
                    <DT><A HREF="https://nd101.slack.com/messages/keras/" >Udacity-DL Slack</A>
                    <DT><A HREF="https://discussions.udacity.com/c/nd101-Project-1/" >UdacityDL Forums</A>
                    <DT><A HREF="https://s3-us-west-2.amazonaws.com/udacity-email/Documents/Deep+Learning+Foundations+Student+Handbook.pdf?utm_medium=email&utm_campaign=deep-learning-nd-foundation-welcome-email&utm_source=blueshift&utm_content=dlfnd_welcomeemail&bsft_eid=c285c6ce-5c92-4ae5-8ee3-2bc84ff369f6&bsft_clkid=54cc4c9f-d5ff-498c-8560-cf6a6e7abaca&bsft_uid=15017e6e-bac3-45f4-99d2-6c331d258c62&bsft_mid=6c9870fc-fe11-44ad-8f2e-386660000df8&bsft_txnid=da2e90a3-7ef9-4fb8-bd51-30079e7f2a72" >Udacity-DL Student Handbook</A>
                    <DT><A HREF="http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=2,8&seed=0.64258&showTestData=false&discretize=false&percTrainData=50&x=false&y=false&xTimesY=true&xSquared=true&ySquared=true&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false" >A Neural Network Playground</A>
                    <DT><A HREF="http://sebastianruder.com/optimizing-gradient-descent/index.html#momentum" >An overview of ... Momentum</A>
                    <DT><A HREF="https://www.youtube.com/watch?v=Gj0iyo265bc&list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal" >Google TensorFlow Series</A>
                    <DT><A HREF="https://www.youtube.com/watch?v=HgLplBRpRcs" >Live Q&amp;A with the Deep Learning Foundations Team - YouTube</A>
                    <DT><A HREF="https://www.youtube.com/watch?v=hhJIztWR_vo" >How to Use Tensorflow for Time Series (Live) - YouTube</A>
                </DL><p>
                <DT><H3 >MIT Self-Driving Car</H3>
                <DL><p>
                    <DT><A HREF="http://selfdrivingcars.mit.edu/deeptesla/" >DeepTesla Tutorial</A>
                    <DT><A HREF="https://github.com/lexfridman/deeptesla" >GitHub - lexfridman/deeptesla</A>
                    <DT><A HREF="http://selfdrivingcars.mit.edu/deeptraffic/" >DeepTraffic </A>
                </DL><p>
                <DT><H3 >Udacity__Intro-to-DL</H3>
                <DL><p>
                    <DT><A HREF="https://classroom.udacity.com/courses/ud730/lessons/6370362152/concepts/63798118150923" >Take this 1st: DL</A>
                </DL><p>
                <DT><H3 >cs231n: CNNs for VizRec</H3>
                <DL><p>
                    <DT><A HREF="http://cs231n.stanford.edu/" >2016 Main Page</A>
                    <DT><A HREF="http://cs231n.github.io/convolutional-networks/" >2016 Notes on GitHub</A>
                </DL><p>
                <DT><A HREF="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html" >UCL Course on Reinforcement Learning (2015)</A>
                <DT><A HREF="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/" >2015:  Machine Learning (DL, CNN, RNN, RL, etc)</A>
                <DT><A HREF="http://rll.berkeley.edu/deeprlcourse/" >2017: UCB-cs294: Deep Reinforcement Learning</A>
                <DT><A HREF="http://rll.berkeley.edu/deeprlcourse-fa15/" >2015:  UCB-cs294: Deep Reinforcement Learning (abbv version of 2017 course)</A>
                <DT><A HREF="http://www.trivedigaurav.com/blog/quoc-les-lectures-on-deep-learning/" >Quoc Le’s Lectures on Deep Learning</A>
                <DT><A HREF="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0" >TensorFlow and deep learning, without a PhD</A>
                <DT><A HREF="https://github.com/alrojo/tensorflow-tutorial" >Practical tutorials and labs for TensorFlow used by Nvidia, FFN, CNN, RNN, Kaggle, AE</A>
                <DT><A HREF="https://www.youtube.com/watch?v=LFDU2GX4AqM&utm_medium=email&utm_campaign=deep-learning-nd-foundation-welcome-email&utm_source=blueshift&utm_content=dlfnd_welcomeemail&bsft_eid=c285c6ce-5c92-4ae5-8ee3-2bc84ff369f6&bsft_clkid=6dfa0477-f009-40c8-9997-27fe779f78e5&bsft_uid=15017e6e-bac3-45f4-99d2-6c331d258c62&bsft_mid=6c9870fc-fe11-44ad-8f2e-386660000df8&bsft_txnid=da2e90a3-7ef9-4fb8-bd51-30079e7f2a72" >Watch this: Ng Overview of DL</A>
                <DT><A HREF="https://www.udacity.com/course/introduction-to-computer-vision--ud810" >Rec: Intro to Comp Vision</A>
                <DT><A HREF="https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373" >Rec:  AI for Robotics</A>
                <DT><A HREF="http://cs231n.stanford.edu/syllabus.html" >Stanford: ConvNN for Visual Recognition</A>
                <DT><A HREF="https://joanbruna.github.io/stat212b/" >Stat212b: Topics Course on Deep Learning by joanbruna</A>
                <DT><A HREF="https://www.coursera.org/learn/neural-networks" >Neural Networks for Machine Learning - University of Toronto | Coursera</A>
                <DT><A HREF="http://cs231n.github.io/" >CS231n Convolutional Neural Networks for Visual Recognition</A>
                <DT><A HREF="https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC" >CS231n Winter 2016 - YouTube</A>
                <DT><A HREF="http://rll.berkeley.edu/deeprlcourse/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=revue" >CS 294 Deep Reinforcement Learning, Spring 2017</A>
            </DL><p>
            <DT><H3 >DataNews</H3>
            <DL><p>
                <DT><A HREF="https://www.getrevue.co/profile/wildml/issues/the-wild-week-in-ai-pytorch-release-poker-ai-leads-over-humans-kristen-stewart-co-authors-dl-paper-42544" >The Wild Week in AI</A>
                <DT><A HREF="http://deeplearning.net/" >DeepLearning.Net</A>
                <DT><A HREF="https://medium.com/transmission-newsletter" >Transmission Newsletter – Medium</A>
                <DT><A HREF="http://www.datatau.com/" >DataTau (ML/DL News)</A>
                <DT><A HREF="http://www.deeplearningweekly.com/" >Deep Learning Weekly</A>
            </DL><p>
            <DT><H3 >DataSets</H3>
            <DL><p>
                <DT><A HREF="http://yann.lecun.com/exdb/mnist/" >MNIST</A>
                <DT><A HREF="http://ufldl.stanford.edu/housenumbers/" >SVHN (Street View House Numbers)</A>
                <DT><A HREF="https://www.cs.toronto.edu/~kriz/cifar.html" >CIFAR-10 and CIFAR-100</A>
            </DL><p>
            <DT><H3 >de/trans CNNs</H3>
            <DL><p>
                <DT><A HREF="http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf" >2010:  Zeiler et al (NYU):  Deconvolutional Networks</A>
                <DT><A HREF="http://cs.nyu.edu/~fergus/drafts/utexas2.pdf" >Zeiler&#39;s Slides on Deconvolutional Networks</A>
                <DT><A HREF="https://www.youtube.com/watch?v=ByjaPdWXKJ4&feature=youtu.be&t=16m59s" >CS231n Winter 2016: Lecture 13: Segmentation, soft attention, spatial transformers - YouTube</A>
                <DT><A HREF="http://datascience.stackexchange.com/questions/6107/what-are-deconvolutional-layers" > What are deconvolutional layers? (Stack Exchange)</A>
            </DL><p>
            <DT><H3 >GANs</H3>
            <DL><p>
                <DT><A HREF="https://arxiv.org/abs/1406.2661" >[1406.2661] Generative Adversarial Networks</A>
                <DT><A HREF="https://arxiv.org/abs/1606.03498" >[1606.03498] Improved Techniques for Training GANs</A>
                <DT><A HREF="https://github.com/openai/improved-gan" >openai/improved-gan: code for the paper &quot;Improved Techniques for Training GANs&quot;</A>
                <DT><A HREF="https://arxiv.org/abs/1606.03657" >[1606.03657] InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</A>
                <DT><A HREF="https://github.com/openai/InfoGAN" >openai/InfoGAN</A>
                <DT><A HREF="https://github.com/Newmu/dcgan_code" >Newmu/dcgan_code: Deep Convolutional Generative Adversarial Networks</A>
                <DT><A HREF="https://arxiv.org/abs/1606.03476" >[1606.03476] Generative Adversarial Imitation Learning</A>
                <DT><A HREF="https://github.com/openai/imitation" >openai/imitation</A>
            </DL><p>
            <DT><H3 >Hardware</H3>
            <DL><p>
                <DT><A HREF="https://www.nvidia.com/en-us/geforce/products/10series/titan-x-pascal/" >NVIDIA TITAN X Graphics Card with Pascal  (what OpenAI uses)</A>
                <DT><A HREF="https://pcpartpicker.com/user/badmephisto/saved/#view=mM3J7P" >Andrew&#39;s Linux Rig</A>
                <DT><A HREF="https://www.oreilly.com/learning/build-a-super-fast-deep-learning-machine-for-under-1000?twitter=@bigdata" >Build a super fast deep learning machine for under $1,000 - O&#39;Reilly Media</A>
            </DL><p>
            <DT><H3 >Home Pages</H3>
            <DL><p>
                <DT><A HREF="http://www.iro.umontreal.ca/~bengioy/yoshua_en/Highlights.html" >Bengio Home Page</A>
                <DT><A HREF="http://cs.stanford.edu/people/karpathy/" >Andrej Karpathy Home Page</A>
                <DT><A HREF="http://www.socher.org/" >Richard Socher - Home Page</A>
                <DT><A HREF="https://twitter.com/gdb" >Greg Brockman (@gdb) | Twitter</A>
                <DT><A HREF="http://www.cs.toronto.edu/~ilya/" >Ilya Sutskever&#39;s home page</A>
                <DT><A HREF="http://www.trevorblackwell.com/#" >Trevor Blackwell | Home Page</A>
                <DT><A HREF="http://dpkingma.com/" >Diederik P. Kingma | Home Page</A>
                <DT><A HREF="http://joschu.net/" >John Schulman&#39;s Homepage</A>
                <DT><A HREF="http://www.dmi.usherb.ca/~larocheh/index_en.html" >Hugo Larochelle | Home Page</A>
                <DT><A HREF="http://cs.nyu.edu/~zaremba/" >Wojciech Zaremba | Home Page</A>
                <DT><A HREF="http://www.cs.stanford.edu/~acoates/papers/acoates_thesis.pdf" >Adam Coates PhD Dissertation</A>
                <DT><A HREF="http://colah.github.io/" >Home - colah&#39;s blog</A>
            </DL><p>
            <DT><H3 >Kernel Methods for DL</H3>
            <DL><p>
                <DT><A HREF="http://cseweb.ucsd.edu/~saul/papers/nips09_kernel.pdf" >2009:  Cho:  Kernel Methods for Deep Learning</A>
                <DT><A HREF="http://jmlr.org/papers/volume12/montavon11a/montavon11a.pdf" >2011:  Montavon:  Kernel Analysis of Deep Networks</A>
            </DL><p>
            <DT><H3 >NLP</H3>
            <DL><p>
                <DT><A HREF="https://www.youtube.com/watch?v=wTp3P2UnTfQ" >Word2Vec &amp; Friends (YouTube)</A>
                <DT><A HREF="https://arxiv.org/abs/1301.3781" >2013:  Mikolov et al:  Efficient Estimation of Word Representations in Vector Space  (Word2Vec)</A>
                <DT><A HREF="https://arxiv.org/abs/1402.3722" >2014:  Goldberg &amp; Levy:  word2vec Explained: deriving Mikolov et al.&#39;s negative-sampling word-embedding method</A>
                <DT><A HREF="https://en.wikipedia.org/wiki/Word2vec" >Word2vec - Wikipedia</A>
                <DT><A HREF="https://en.wikipedia.org/wiki/Word_embedding" >Word embedding - Wikipedia</A>
                <DT><A HREF="http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/" >2014:  Olah:  Deep Learning, NLP, and Representations</A>
                <DT><A HREF="http://www.iro.umontreal.ca/~lisa/pointeurs/turian-wordrepresentations-acl10.pdf" >2010:  Turian et al:  Word Representations:  A simple and general method for semi-supervised learning</A>
                <DT><A HREF="http://www.iro.umontreal.ca/~lisa/publications2/index.php/publications/show/64" >2001:  Bengio et al: A Neural Probabilistic Language Model - LISA - Publications - Aigaion 2.0</A>
                <DT><A HREF="http://machinelearning.wustl.edu/mlpapers/paper_files/BengioDVJ03.pdf" >2003:  Bengio et al:  A Neural Probabilistic Language Model</A>
                <DT><A HREF="http://nlp.stanford.edu/~lmthang/data/papers/conll13_morpho.pdf" >2013:  Luong et al:  Better word representations w/ RNNs for Morphology  (pdf)</A>
                <DT><A HREF="https://arxiv.org/pdf/1312.5650.pdf" >2014:  Norouzi et al:  Zero-shot learning by convex combination of semantic embeddings</A>
                <DT><A HREF="https://arxiv.org/pdf/1103.0398v1.pdf" >2011:  Collobert et al:  NLP (almost) from Scratch</A>
                <DT><A HREF="http://cs224d.stanford.edu/syllabus.html" >Standford Course: Deep Learning for NLP</A>
                <DT><A HREF="http://web.stanford.edu/class/cs224n/" >Stanford Course: NLP with Deep Learning  (most recent)</A>
                <DT><A HREF="https://www.microsoft.com/en-us/research/publication/linguistic-regularities-in-continuous-space-word-representations/?from=http%3A%2F%2Fresearch.microsoft.com%2Fpubs%2F189726%2Frvecs.pdf" >2013:  Mikolov et al:  Linguistic Regularities in Continuous Space Word Representations</A>
                <DT><A HREF="https://arxiv.org/abs/1412.5567" >2014:  Hannun et al:  Deep Speech: Scaling up end-to-end speech recognition</A>
                <DT><A HREF="https://arxiv.org/abs/1512.02595" >2015:  Amodei et al:  Deep Speech 2: End-to-End Speech Recognition in English and Mandarin</A>
                <DT><A HREF="https://arxiv.org/abs/1611.04558" >[1611.04558] Google&#39;s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation</A>
                <DT><A HREF="https://www.aclweb.org/anthology/J/J11/J11-2001.pdf" >Lexicon-Based Methods for Sentiment Analysis</A>
                <DT><A HREF="https://cs224d.stanford.edu/reports/HongJames.pdf" >Sentiment Analysis w/ Deeply Learned Distributed Representations of Variable Length Texts</A>
                <DT><A HREF="https://cs.stanford.edu/~quocle/paragraph_vector.pdf" >Distributed Representations of Sentences and Documents</A>
                <DT><A HREF="http://deeplearning.net/tutorial/lstm.html" >LSTM Networks for Sentiment Analysis</A>
            </DL><p>
            <DT><H3 >OpenAI</H3>
            <DL><p>
                <DT><A HREF="https://openai.com/blog/openai-gym-beta/" >OpenAI Gym</A>
                <DT><A HREF="https://gym.openai.com/envs/Ant-v1" >Ant-v1</A>
                <DT><A HREF="https://gym.openai.com/docs" >OpenAI Gym:  Documentation</A>
                <DT><A HREF="https://gym.openai.com/envs/Humanoid-v1" >Humanoid-v1</A>
                <DT><A HREF="https://openai.com/blog/" >Blog</A>
                <DT><A HREF="https://openai.com/requests-for-research/" >Requests for Research</A>
                <DT><A HREF="https://openai.com/jobs/" >Jobs at OpenAI</A>
                <DT><A HREF="https://universe.openai.com/envs#flash_games" >Gaming Environments</A>
                <DT><A HREF="https://discuss.openai.com/categories" >OpenAI Forum</A>
                <DT><A HREF="https://discuss.openai.com/t/nips-2016-openai-schedule/243" >NIPS 2016 OpenAI Schedule</A>
                <DT><A HREF="https://github.com/openai/universe-starter-agent" >openai/universe-starter-agent</A>
                <DT><A HREF="https://www.wired.com/2016/04/openai-elon-musk-sam-altman-plan-to-set-artificial-intelligence-free/" >Inside OpenAI, Elon Musk’s Wild Plan to Set Artificial Intelligence Free | WIRED</A>
            </DL><p>
            <DT><H3 >Q/Reinforcement Learning</H3>
            <DL><p>
                <DT><A HREF="http://karpathy.github.io/2016/05/31/rl/" >Deep Reinforcement Learning: Pong from Pixels</A>
                <DT><A HREF="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" >UCL Course on Reinforcement Learning</A>
                <DT><A HREF="https://arxiv.org/abs/1605.09674" >[1605.09674] VIME: Variational Information Maximizing Exploration</A>
                <DT><A HREF="https://github.com/openai/vime" >openai/vime</A>
            </DL><p>
            <DT><H3 >Quasi-RNNs</H3>
            <DL><p>
                <DT><A HREF="https://arxiv.org/abs/1611.01576" >2016:  Bradbury et al:  Quasi-Recurrent Neural Networks</A>
            </DL><p>
            <DT><H3 >RecEngPapers</H3>
            <DL><p>
                <DT><A HREF="https://pdfs.semanticscholar.org/4552/ba5ac5cbb6c556ebd228c8f9116b46793bc2.pdf" >Proceedings of the RecSys 2011 Workshop on Human Decision Making in Recommender Systems (Decisions@RecSys’11) and User‐Centric Evaluation of Recommender Systems and Their Interfaces ‐ 2 (UCERSTI 2) affiliated with the 5th ACM Conference on Recommend</A>
                <DT><A HREF="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.705.9655&rep=rep1&type=pdf" >download</A>
                <DT><A HREF="http://delivery.acm.org/10.1145/2850000/2843948/a13-gomez-uribe.pdf?ip=74.201.147.254&id=2843948&acc=OA&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2EE5B8A747884E71D5&CFID=870776299&CFTOKEN=40950884&__acm__=1480620930_981c2cf1cbe774ac08c7ca72f1a91a72" >a13-gomez-uribe.pdf</A>
                <DT><A HREF="http://recprofile.org/bingham-walker.pdf" >bingham-walker.pdf</A>
                <DT><A HREF="http://ls13-www.cs.tu-dortmund.de/homepage/publications/jannach/Conference_UMAP_2016_re.pdf" >Conference_UMAP_2016_re.pdf</A>
                <DT><A HREF="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.650.4684&rep=rep1&type=pdf" >SIG-039-Perfect.indd</A>
                <DT><A HREF="https://arxiv.org/pdf/1409.2944.pdf" >1409.2944.pdf</A>
                <DT><A HREF="http://www.redes.unb.br/lasp/files/events/ICASSP2014/papers/p7014-dieleman.pdf" >End-to-end learning for music audio</A>
                <DT><A HREF="https://pdfs.semanticscholar.org/b2e9/2ac358cda4a17f72e23711b9bbc1a044729e.pdf" >Improving Content-based and Hybrid Music Recommendation using Deep Learning</A>
                <DT><A HREF="http://karol.piczak.com/papers/Piczak2015-ESC-ConvNet.pdf" >Piczak2015-ESC-ConvNet.pdf</A>
                <DT><A HREF="http://www.few.vu.nl/en/Images/werkstuk-hoven_tcm244-748599.pdf" >Analyzing Spotify Data</A>
                <DT><A HREF="http://ls13-www.cs.tu-dortmund.de/homepage/publications/jannach/Workshop_RSWEB_2014.pdf" >Workshop_RSWEB_2014.pdf</A>
                <DT><A HREF="http://www.cs.northwestern.edu/~pardo/courses/mmml/papers/collaborative_filtering/FIVE_APPROACHES_TO_COLLECTING_TAGS_FOR_MUSIC_ISMIR08.pdf" >FIVE_APPROACHES_TO_COLLECTING_TAGS_FOR_MUSIC_ISMIR08.pdf</A>
                <DT><A HREF="https://scholar.google.com/scholar?q=related:wSk6iGfKs_UJ:scholar.google.com/&hl=en&as_sdt=0,7" >Gomez-Uribe: The Netflix recommender system: Algorithms,... - Google Scholar</A>
            </DL><p>
            <DT><H3 >Relations to Physics</H3>
            <DL><p>
                <DT><A HREF="http://www.cs.yale.edu/publications/techreports/tr1226.pdf" >Path Integrals of Information (pdf)</A>
                <DT><A HREF="https://pdfs.semanticscholar.org/197f/137c0174141d65418502e8702281281cdf3a.pdf" >Path integral guided policy search</A>
                <DT><A HREF="http://www.sciencedirect.com/science/article/pii/S0196885805000850" >A neural network wave formalism - ScienceDirect</A>
                <DT><A HREF="https://www.quora.com/What-are-the-connections-between-machine-learning-and-physics" >What are the connections between machine learning and physics? - Quora</A>
                <DT><A HREF="https://www.quantamagazine.org/20141204-a-common-logic-to-seeing-cats-and-cosmos/" >Deep Learning Relies on Renormalization, Physicists Find | Quanta Magazine</A>
                <DT><A HREF="https://calculatedcontent.com/2015/04/01/why-deep-learning-works-ii-the-renormalization-group/" >Why Deep Learning Works II: the Renormalization Group – CALCULATED CONTENT</A>
                <DT><A HREF="http://timdettmers.com/2015/03/26/convolution-deep-learning/" >Understanding Convolution in Deep Learning (It&#39;s all fluid dynamics, QM, etc)</A>
                <DT><A HREF="http://stats.stackexchange.com/questions/198061/why-the-sudden-fascination-with-tensors" >machine learning - Why the sudden fascination with tensors? - Cross Validated</A>
                <DT><A HREF="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/" >Neural Networks, Manifolds, and Topology</A>
                <DT><A HREF="https://arxiv.org/pdf/1608.08225.pdf" >Paper: Why does deep/cheap learning work so well?  (Lin&amp;Tegmark2016)</A>
                <DT><A HREF="https://arxiv.org/abs/1410.3831" >[1410.3831] An exact mapping between the Variational Renormalization Group and Deep Learning</A>
            </DL><p>
            <DT><H3 >RNNs</H3>
            <DL><p>
                <DT><A HREF="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" >Understanding LSTM Networks</A>
                <DT><A HREF="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" >The Unreasonable Effectiveness of Recurrent Neural Networks</A>
                <DT><A HREF="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" >1994:  Bengio et al:  Learning long-term dependencies with gradient descent is difficult  (synopsis:  why standard RNNs are good in theory, but suck in practice)</A>
                <DT><A HREF="https://www.researchgate.net/publication/13853244_Long_Short-term_Memory" >1997:  Hochreiter &amp; Schmidhuber:  Long Short-term Memory  (i.e., the new, non-sucky RNN)</A>
                <DT><A HREF="http://distill.pub/2016/augmented-rnns/" >2016:  Olah &amp; Carter:  Attention and Augmented Recurrent Neural Networks</A>
                <DT><A HREF="https://arxiv.org/abs/1601.06759" >[1601.06759] Pixel Recurrent Neural Networks</A>
                <DT><A HREF="https://arxiv.org/pdf/1602.02410v2.pdf" >Exploring the Limits of Language Modeling</A>
                <DT><A HREF="https://www.youtube.com/watch?v=iX5V1WpxxkY" >CS231n Lecture 10 - Recurrent Neural Networks, Image Captioning, LSTM - YouTube</A>
                <DT><A HREF="http://www.deeplearningbook.org/contents/rnn.html" >DLBook: Ch10:  Sequence Modeling w/ Recurrent and Recursive Nets</A>
                <DT><A HREF="http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf" >1997:  Hochreiter &amp; Schmidhuber:  Long Short-Term Memory</A>
                <DT><A HREF="https://pdfs.semanticscholar.org/3e5d/2d0d5bf450728c8f21df6f921a975c339c45.pdf" >1999: Gers, Schmidhuber &amp; Cummins:  Learning to Forget</A>
                <DT><A HREF="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.463.9126&rep=rep1&type=pdf" >2008:  Graves:  Supervised Sequence Labelling w/ RNNs (Dissertation)</A>
                <DT><A HREF="https://arxiv.org/pdf/1506.00019.pdf" >A Critical Review of RNNs for Sequence Learning</A>
                <DT><A HREF="https://arxiv.org/pdf/1506.02078.pdf" >2016:  Karpathy, Johson, Fei-Fei:  Visualizing and Understanding RNNs</A>
                <DT><A HREF="http://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html" >Written Memories: Understanding, Deriving and Extending the LSTM - R2RT</A>
            </DL><p>
            <DT><H3 >Style Transfer</H3>
            <DL><p>
                <DT><A HREF="https://arxiv.org/abs/1508.06576" >A Neural Algorithm of Artistic Style</A>
                <DT><A HREF="http://cs.stanford.edu/people/jcjohns/eccv16/" >Perceptual Losses for Real-Time Style Transfer and Super-Resolution</A>
                <DT><A HREF="https://arxiv.org/abs/1607.08022" >Instance Normalization</A>
                <DT><A HREF="https://github.com/lengstrom/fast-style-transfer" >GitHub - lengstrom/fast-style-transfer: Fast Style Transfer in TensorFlow! ⚡🖥🎨🖼</A>
                <DT><A HREF="https://drive.google.com/drive/folders/0B9jhaT37ydSyRk9UX0wwX3BpMzQ" >Fast Style Transfer Models - Google Drive</A>
            </DL><p>
            <DT><H3 >VAEs</H3>
            <DL><p>
                <DT><A HREF="https://www.cs.jhu.edu/~jason/tutorials/variational.html" >High-Level Explanation of Variational Inference</A>
                <DT><A HREF="http://www.cs.princeton.edu/courses/archive/spr06/cos598C/papers/chapter2.pdf" >Blei2004.pdf</A>
                <DT><A HREF="https://arxiv.org/abs/1505.05770" >[1505.05770] Variational Inference with Normalizing Flows</A>
                <DT><A HREF="https://arxiv.org/abs/1312.6114" >[1312.6114] Auto-Encoding Variational Bayes</A>
                <DT><A HREF="https://arxiv.org/abs/1502.04623" >[1502.04623] DRAW: A Recurrent Neural Network For Image Generation</A>
                <DT><A HREF="https://arxiv.org/abs/1603.08575" >[1603.08575] Attend, Infer, Repeat: Fast Scene Understanding with Generative Models</A>
                <DT><A HREF="http://www.iro.umontreal.ca/~lisa/pointeurs/ICML2011_explicit_invariance.pdf" >2011:  Rifai et al:  Contractive Auto-Encoders: Explicit Invariance During Feature Extraction</A>
            </DL><p>
            <DT><A HREF="https://arxiv.org/pdf/1606.05340v2.pdf" >Exponential expressivity in deep neural networks through transient chaos  (PDF)</A>
            <DT><H3 >SOMs</H3>
            <DL><p>
                <DT><A HREF="http://www.cs.bham.ac.uk/~jxb/NN/l16.pdf" >SOM: Fundamentals (from jxb notes)</A>
                <DT><A HREF="http://www.cs.bham.ac.uk/~jxb/NN/l17.pdf" >SOMs: Algorithms &amp; Applications (from jxb notes)</A>
                <DT><A HREF="http://www.ai-junkie.com/ann/som/som1.html" >SOM tutorial part 1</A>
                <DT><A HREF="https://en.wikipedia.org/wiki/Self-organizing_map" >Self-organizing map - Wikipedia</A>
                <DT><A HREF="https://codesachin.wordpress.com/2015/11/28/self-organizing-maps-with-googles-tensorflow/" >Self-Organizing Maps with Google’s TensorFlow | Sachin Joglekar&#39;s blog</A>
            </DL><p>
            <DT><H3 >Scale/Rot-Inv DL</H3>
            <DL><p>
                <DT><A HREF="http://www.umiacs.umd.edu/~kanazawa/papers/sicnn_workshop2014.pdf" >2014: Kanazawa et al:  Locally Scale-Invariant Convolutional Neural Networks</A>
                <DT><A HREF="http://cs231n.stanford.edu/reports2016/107_Report.pdf" >Quantifying translation-invariance in CNNs</A>
                <DT><A HREF="https://arxiv.org/pdf/1604.06720.pdf" >2016:  Marcos et al:  Learning rotation invariant convolutional filters for texture classification</A>
                <DT><A HREF="http://theorycenter.cs.uchicago.edu/REU/2014/final-papers/sauder.pdf" >Encoded invariance in CNNs</A>
                <DT><A HREF="http://www.idiap.ch/~gatica/publications/FaselGatica-icpr06.pdf" >Rotation-invariant neoperceptron</A>
                <DT><A HREF="https://github.com/akanazawa/si-convnet" >akanazawa/si-convnet: Implementation of the [Locally Scale-Invariant Convolutional Neural Network](http://www.umiacs.umd.edu/~kanazawa/papers/sicnn_workshop2014.pdf)</A>
                <DT><A HREF="http://dl.acm.org/citation.cfm?id=2964316" >Transform-Invariant Convolutional Neural Networks for Image Classification and Search</A>
            </DL><p>
            <DT><A HREF="https://arxiv.org/pdf/1402.5836.pdf" >2016:  Duvenaud:  Avoiding pathologies in very deep networks</A>
            <DT><A HREF="http://cs.nyu.edu/~zaremba/docs/understanding.pdf" >2013:  Szegedy et al:  Intriguing properties of neural networks</A>
            <DT><A HREF="http://cs.stanford.edu/people/karpathy/ilsvrc/" >Can you beat a computer?  (Karpathy&#39;s image test)</A>
            <DT><A HREF="https://translate.google.com/" >Google Translate</A>
            <DT><A HREF="https://www.mturk.com/mturk/welcome" >Amazon Mechanical Turk </A>
            <DT><A HREF="https://www.crowdflower.com/" >CrowdFlower (AI for your Biz)</A>
            <DT><A HREF="https://www.microsoft.com/en-us/research/project/project-malmo/" >Project Malmo  (Microsoft)</A>
            <DT><A HREF="https://www.tensorflow.org/versions/r0.10/how_tos/summaries_and_tensorboard/" >TensorBoard</A>
            <DT><A HREF="http://mscoco.org/" >MS COCO  (Common Objects in Context)</A>
            <DT><A HREF="https://gab41.lab41.org/" >Gab41</A>
            <DT><A HREF="http://www.wildml.com/" >WildML – AI, Deep Learning, NLP</A>
            <DT><A HREF="http://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html" >ConvNetJS Deep Q Demo</A>
            <DT><A HREF="http://cs.stanford.edu/people/karpathy/convnetjs/" >ConvNetJS: Deep Learning in your browser</A>
            <DT><A HREF="http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf" >Google&#39;s ML Style Guide</A>
            <DT><A HREF="http://pages.cs.wisc.edu/~dyer/cs540/handouts/deep-learning-nature2015.pdf" >DL (small review paper: LeCun, Bengio, &amp; Hinton)</A>
            <DT><A HREF="https://github.com/terryum/awesome-deep-learning-papers" >List of Most-Cited DL/ML papers</A>
            <DT><A HREF="https://www.floydhub.com/" >Floyd Zero Setup Deep Learning</A>
            <DT><A HREF="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf" >Dropout: A Simple Way to Prevent NNs from Overfitting</A>
            <DT><A HREF="https://arxiv.org/abs/0908.4425" >[0908.4425] Geometry of the restricted Boltzmann machine</A>
            <DT><A HREF="http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf" >Practical Guide to Training Restricted Boltzmann Machines</A>
            <DT><A HREF="http://benanne.github.io/2014/08/05/spotify-cnns.html" >Recommending music on Spotify with deep learning – Sander Dieleman</A>
        </DL><p>
